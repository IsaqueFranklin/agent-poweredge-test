Recently langchain was divided into multiple module packages.

- langchain-core: The heart of the framework. It defines the fundamental interfaces — such as language models, “runnables,” and message schemas like HumanMessage and AIMessage.
- langchain-community: Contains all community and third-party integrations (for example: OpenAI, Ollama, MongoDB, etc.). This is where integrations like ChatOllama live, as well as vector store integrations such as Chroma, FAISS, and MongoDB Atlas Vector Search.
- langchain: The main orchestration library. It imports langchain-core and provides higher-level abstractions and components, including:
    * Models (LLMs / ChatModels) – Interfaces for communicating with models (e.g., ChatOllama).
    * Prompts – Templates for creating structured instructions sent to the model (e.g., ChatPromptTemplate).
    * Tools – Functions or utilities that an agent can choose to use (e.g., DuckDuckGoSearchRun).
    * Agents – The decision-making brain that coordinates LLMs and tools.
    * Chains – Simple sequential workflows (for example, a prompt + a model is the simplest chain).
- langchain-partners (e.g., langchain-openai, langchain-google-genai): Provider-specific packages for major AI platforms and services.

Why Gunicorn is not right for RAG prod workers?
It will create one copy of my rag for each worker, which will make my ram or vram explode. Each Gunicorn worker is an exact copy of my api+rag.
The services need to be separated. Very few workers for the RAG and many workers for the API.

The Correct Flow
- User sends a request to yourapi.com/query.
- Nginx (Waiter) delivers the request to Gunicorn (Manager).
- Gunicorn hands it off to a lightweight API Worker (Chef).
- The API Worker (Chef) realizes it needs the RAG. It sends an internal request to http://localhost:5001/generate (the Central Bakery).
- The RAG Service (Baker at the Industrial Oven) processes the request and returns the response.
- The API Worker (Chef) receives the response, finishes the dish, and returns it to Gunicorn.
- Gunicorn returns it to Nginx, which delivers it to the User.